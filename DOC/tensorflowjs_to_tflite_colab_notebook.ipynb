{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflowjs_to_tflite_colab_notebook.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "yVMF3Q_HnJ09",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Install Dependencies**"
      ]
    },
    {
      "metadata": {
        "id": "FbMsNJ4PAq2j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install tensorflow==1.10.1 keras==2.2.2 tensorflowjs==0.6.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WZGFStffPj_Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import traceback\n",
        "import logging\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "from keras import Model, Input\n",
        "from keras.applications import MobileNet\n",
        "from keras.engine.saving import load_model\n",
        "\n",
        "from tensorflow.python.framework import graph_util, graph_io\n",
        "from tensorflowjs.converters import load_keras_model\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lh7zgNXVx8ML",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***Cleanup any existing models if necessary***"
      ]
    },
    {
      "metadata": {
        "id": "JrMA8frMx7aa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!!rm -rf *.h5 *.tflite *.json *.bin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ct36DONNnNZJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Upload your Tensorflow.js Artifacts Here**\n",
        "\n",
        "i.e., The weights manifest **model.json** and the binary weights file **model-weights.bin**"
      ]
    },
    {
      "metadata": {
        "id": "s-_80hGtMTFb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_ctAZ--FnStM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Export Configuration**"
      ]
    },
    {
      "metadata": {
        "id": "hrzzoZP5oK7S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Export Configuration\n",
        "\n",
        "# TensorFlow.js arguments\n",
        "\n",
        "config_json = \"model.json\" #@param {type:\"string\"}\n",
        "weights_path_prefix = \".\" #@param {type:\"string\"}\n",
        "load_weights = True #@param {type:\"boolean\"}\n",
        "use_unique_name_scope = True #@param {type:\"boolean\"}\n",
        "\n",
        "# MobileNet model options\n",
        "\n",
        "input_node_name = \"the_input\" #@param {type:\"string\"}\n",
        "alpha = 0.25 #@param {type:\"slider\", min:0.25, max:1, step:0.25}\n",
        "image_size = 224 #@param [\"128\", \"160\", \"192\", \"224\"] {type:\"raw\"}\n",
        "intermediate_node_name = \"conv_pw_13_relu\" #@param {type:\"string\"}\n",
        "\n",
        "# Frozen Graph options\n",
        "output_node_prefix = \"output_node\" #@param {type:\"string\"}\n",
        "\n",
        "# Path to exported models\n",
        "keras_model_file= \"model.h5\" #@param {type:\"string\"}\n",
        "frozen_model_file = \"model.pb\" #@param {type:\"string\"}\n",
        "tflite_model_file = \"model.tflite\" #@param {type:\"string\"}\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RA0iINpNiK_p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Model Converter**\n",
        "\n",
        "The following class converts a TensorFlow.js model to a TFLite FlatBuffer"
      ]
    },
    {
      "metadata": {
        "id": "8QMjVgxVggQJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ModelConverter:\n",
        "    \"\"\"\n",
        "    Creates a ModelConverter class from a TensorFlow.js model file.\n",
        "\n",
        "    Args:\n",
        "      config_json_path: Full filepath of weights manifest file containing the model architecture.\n",
        "      weights_path_prefix: Full filepath to the directory in which the weights binaries exist.\n",
        "      use_unique_name_scope: Use a unique ID as the name scope for the loaded model.\n",
        "      tflite_model_file: Name of the TFLite FlatBuffer file to be exported.\n",
        "\n",
        "    Returns:\n",
        "      ModelConverter class.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 config_json_path,\n",
        "                 weights_path_prefix,\n",
        "                 use_unique_name_scope,\n",
        "                 tflite_model_file\n",
        "                 ):\n",
        "        self.config_json_path = config_json_path\n",
        "        self.weights_path_prefix = weights_path_prefix\n",
        "        self.use_unique_name_scope = use_unique_name_scope\n",
        "\n",
        "        self.input_node_name = None\n",
        "        self.intermediate_node_name = None\n",
        "        self.output_node_name = None\n",
        "\n",
        "        self.tflite_model_file = tflite_model_file\n",
        "\n",
        "    def convert(self, keras_model_file, output_node_prefix, frozen_model_file):\n",
        "        frozen_model_file = self._freeze_graph_from_keras(keras_model_file,\n",
        "                                                          output_node_prefix,\n",
        "                                                          frozen_model_file=frozen_model_file,\n",
        "                                                          num_outputs=1)\n",
        "\n",
        "        self._deserialize_tflite_from_frozen_graph(frozen_model_file,\n",
        "                                                   self.input_node_name,\n",
        "                                                   self.output_node_name,\n",
        "                                                   self.tflite_model_file)\n",
        "\n",
        "        logger.info('The TFLite model has been generated')\n",
        "\n",
        "    def save_keras_model(self, keras_model_file, **kwargs):\n",
        "        \"\"\"\n",
        "        Converts a Keras model to a frozen TensorFlow Protocol Buffer.\n",
        "\n",
        "        Args:\n",
        "            keras_model_file: Filename of the Keras H5 model to be saved\n",
        "            input_node_name: Name of the input layer for the model being built\n",
        "            intermediate_node_name: Name of the intermediate Depthwise Convolutional Block in the base model (MobileNet)\n",
        "            image_size: Size of the input image\n",
        "            alpha: Width of the MobileNet network\n",
        "        \"\"\"\n",
        "        top_model = load_keras_model(self.config_json_path, self.weights_path_prefix,\n",
        "                                     weights_data_buffers=None,\n",
        "                                     load_weights=True,\n",
        "                                     use_unique_name_scope=self.use_unique_name_scope)\n",
        "        base_model = self.build_base_model(**kwargs)\n",
        "        merged_model = self.merge(base_model, top_model)\n",
        "        merged_model.save(keras_model_file)\n",
        "        logger.info(\"Keras HDF5 saved to {}\".format(keras_model_file))\n",
        "\n",
        "    def merge(self, base_model, top_model):\n",
        "        logger.info(\"Creating model...\")\n",
        "        layer = base_model.get_layer(self.intermediate_node_name)\n",
        "        model = Model(inputs=base_model.input, outputs=top_model(layer.output))\n",
        "        return model\n",
        "\n",
        "    def build_base_model(self,\n",
        "                         depth_multiplier=1,\n",
        "                         **kwargs):\n",
        "        self.input_node_name = kwargs.get('input_node_name')\n",
        "        self.intermediate_node_name = kwargs.get('intermediate_node_name')\n",
        "\n",
        "        image_size = kwargs.get('image_size')\n",
        "        alpha = kwargs.get('alpha')\n",
        "        input_shape = (image_size, image_size, 3)\n",
        "\n",
        "        input_tensor = Input(shape=input_shape, name=self.input_node_name)\n",
        "        base_model = MobileNet(input_shape=input_shape,\n",
        "                               alpha=alpha,\n",
        "                               depth_multiplier=depth_multiplier,\n",
        "                               input_tensor=input_tensor,\n",
        "                               include_top=False)\n",
        "        return base_model\n",
        "\n",
        "    def _freeze_graph_from_keras(self, model_file,\n",
        "                                 output_node_prefix,\n",
        "                                 output_folder='.',\n",
        "                                 frozen_model_file=\"model.pb\",\n",
        "                                 num_outputs=1\n",
        "                                 ):\n",
        "        K.clear_session()\n",
        "        K.set_learning_phase(0)\n",
        "        K.set_image_data_format('channels_last')\n",
        "\n",
        "        model = load_model(model_file, compile=False)\n",
        "        sess = K.get_session()\n",
        "\n",
        "        pred = [None] * num_outputs\n",
        "        pred_node_names = [None] * num_outputs\n",
        "\n",
        "        for i in range(num_outputs):\n",
        "            pred_node_names[i] = output_node_prefix + str(i)\n",
        "            pred[i] = tf.identity(model.outputs[i], name=pred_node_names[i])\n",
        "\n",
        "        logger.info('Output nodes names are: {}'.format(pred_node_names))\n",
        "\n",
        "        self.output_node_name = pred_node_names[0]\n",
        "\n",
        "        constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph.as_graph_def(), pred_node_names)\n",
        "        graph_io.write_graph(constant_graph, '.', frozen_model_file, as_text=False)\n",
        "        logger.info('Saved the frozen graph (ready for inference) at: {}'\n",
        "                     .format(str(Path(output_folder) / frozen_model_file)))\n",
        "\n",
        "        return frozen_model_file\n",
        "\n",
        "    @staticmethod\n",
        "    def _deserialize_tflite_from_frozen_graph(frozen_model_file,\n",
        "                                              input_node_name,\n",
        "                                              output_node_name,\n",
        "                                              tflite_model_file):\n",
        "        K.clear_session()\n",
        "\n",
        "        input_arrays = [input_node_name]\n",
        "        output_arrays = [output_node_name]\n",
        "\n",
        "        converter = tf.contrib.lite.TocoConverter.from_frozen_graph(\n",
        "            frozen_model_file, input_arrays, output_arrays)\n",
        "        tflite_model = converter.convert()\n",
        "\n",
        "        with open(tflite_model_file, \"wb\") as file:\n",
        "            file.write(tflite_model)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qUeoHM-Jg7uv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "try:\n",
        "    converter = ModelConverter(args.config_json_path,\n",
        "                               args.weights_path_prefix,\n",
        "                               args.use_unique_name_scope,\n",
        "                               args.tflite_model_file)\n",
        "\n",
        "    converter.save_keras_model(args.keras_model_file,\n",
        "                               input_node_name=args.input_node_name,\n",
        "                               intermediate_node_name=args.intermediate_node_name,\n",
        "                               image_size=args.image_size,\n",
        "                               alpha=args.alpha)\n",
        "\n",
        "    converter.convert(args.keras_model_file, args.output_node_prefix, args.frozen_model_file)\n",
        "\n",
        "except ValueError as e:\n",
        "    print(traceback.format_exc())\n",
        "    print(\"Error occurred while converting\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G7noTBgTg8Fz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download(tflite_model_file)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}